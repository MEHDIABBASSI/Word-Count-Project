{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twinkle', 4),\n",
       " ('wonder', 1),\n",
       " ('are', 1),\n",
       " ('above', 1),\n",
       " ('world', 1),\n",
       " ('high', 1),\n",
       " ('like', 1),\n",
       " ('in', 1),\n",
       " ('sky', 1),\n",
       " ('little', 2),\n",
       " ('star', 2),\n",
       " ('how', 1),\n",
       " ('I', 1),\n",
       " ('what', 1),\n",
       " ('you', 1),\n",
       " ('up', 1),\n",
       " ('the', 2),\n",
       " ('so', 1),\n",
       " ('a', 1),\n",
       " ('diamond', 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importation des librariries et création du sparkContext\n",
    "import pyspark\n",
    "SC = pyspark.SparkContext('local[*]')\n",
    "\n",
    "# Importation des données\n",
    "txt = SC.textFile('sample.txt')\n",
    "\n",
    "# On crée une varible pour mettre le contenu du fichier sous forme\n",
    "# d'un vecteur ou chaque ligne contient un seul mot\n",
    "mots = txt.flatMap(lambda line: line.split(\" \"))\n",
    "mots.collect()\n",
    "\n",
    "# On crée une variable qui contient le mot et son nombre d'occurence dans le fichier\n",
    "wordCount = mots.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b)\n",
    "wordCount.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On export le resultat obtenu dans un fichier text\n",
    "wordCount.saveAsTextFile(\"Result.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
